{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-jhonattan/Treinamento_Rede_Yolo/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics pycocotools requests tqdm pillow\n",
        "\n",
        "import json, random, io, requests, zipfile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "base = Path('.')\n",
        "base_dir = Path('yolo_dataset'); (base_dir/'images/train').mkdir(parents=True, exist_ok=True); (base_dir/'images/val').mkdir(parents=True, exist_ok=True); (base_dir/'labels/train').mkdir(parents=True, exist_ok=True); (base_dir/'labels/val').mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "KKNidvhWADQl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baixar anotações\n",
        "ANN_ZIP='annotations_trainval2017.zip'\n",
        "if not Path(ANN_ZIP).exists():\n",
        "    r=requests.get(\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\", stream=True)\n",
        "    with open(ANN_ZIP,'wb') as f:\n",
        "        for ch in r.iter_content(1<<20):\n",
        "            if ch: f.write(ch)\n",
        "with zipfile.ZipFile(ANN_ZIP,'r') as z:\n",
        "    for n in z.namelist():\n",
        "        if n.endswith('instances_train2017.json') or n.endswith('instances_val2017.json'):\n",
        "            z.extract(n, 'annotations')\n"
      ],
      "metadata": {
        "id": "9IVDUiNxAJqd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers\n",
        "def load_coco(p):\n",
        "    coco=json.loads(Path(p).read_text())\n",
        "    cats={c['id']:c['name'] for c in coco['categories']}\n",
        "    id_by={v:k for k,v in cats.items()}\n",
        "    imgs={im['id']:im for im in coco['images']}\n",
        "    byimg={}\n",
        "    for a in coco['annotations']:\n",
        "        byimg.setdefault(a['image_id'], []).append(a)\n",
        "    return cats,id_by,imgs,byimg\n",
        "\n",
        "cats_tr,id_by_tr,imgs_tr,anns_tr=load_coco('annotations/annotations/instances_train2017.json')\n",
        "cats_va,id_by_va,imgs_va,anns_va=load_coco('annotations/annotations/instances_val2017.json')\n",
        "\n",
        "TARGET=['bicycle','truck']; TIDS=[id_by_tr[c] for c in TARGET]\n",
        "def select(imgs,anns,tids,n):\n",
        "    hit={t:set() for t in tids}\n",
        "    for iid,aa in anns.items():\n",
        "        pres={a['category_id'] for a in aa}\n",
        "        for t in tids:\n",
        "            if t in pres: hit[t].add(iid)\n",
        "    sel=set()\n",
        "    for t in tids:\n",
        "        lst=list(hit[t]); random.shuffle(lst)\n",
        "        for i in lst:\n",
        "            sel.add(i)\n",
        "            if len(hit[t].intersection(sel))>=n: break\n",
        "    return list(sel)\n",
        "\n",
        "train_ids=select(imgs_tr,anns_tr,TIDS,150)\n",
        "val_ids  =select(imgs_va,anns_va,TIDS,40)\n"
      ],
      "metadata": {
        "id": "MwjjaYx_AXLh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dl(ids, imgs, out):\n",
        "    ok=0\n",
        "    for iid in tqdm(ids, desc=f'baixando {out.name}'):\n",
        "        url=imgs[iid].get('coco_url') or imgs[iid].get('flickr_url')\n",
        "        if not url: continue\n",
        "        dest=(base_dir/'images'/out/imgs[iid]['file_name'])\n",
        "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if dest.exists(): continue\n",
        "        resp=requests.get(url,timeout=30); resp.raise_for_status()\n",
        "        Image.open(io.BytesIO(resp.content)).save(dest); ok+=1\n",
        "    print('ok',ok)\n",
        "\n",
        "dl(train_ids, imgs_tr, Path('train'))\n",
        "dl(val_ids,   imgs_va, Path('val'))\n",
        "\n",
        "cls2idx={name:i for i,name in enumerate(TARGET)}\n",
        "def coco2yolo(ids, imgs, anns, outL, outI):\n",
        "    kept=0\n",
        "    for iid in tqdm(ids, desc=f'labels {outL}'):\n",
        "        info=imgs[iid]; imgp=base_dir/'images'/outI/info['file_name']\n",
        "        if not imgp.exists(): continue\n",
        "        W,H=Image.open(imgp).size\n",
        "        lines=[]\n",
        "        for a in anns.get(iid,[]):\n",
        "            if a.get('iscrowd',0)==1 or a['category_id'] not in TIDS: continue\n",
        "            x,y,w,h=a['bbox']; xc=(x+w/2)/W; yc=(y+h/2)/H; wn=w/W; hn=h/H\n",
        "            if wn<=0 or hn<=0: continue\n",
        "            cls=cls2idx[cats_tr[a['category_id']]]; lines.append(f\"{cls} {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\")\n",
        "        if lines:\n",
        "            (base_dir/'labels'/outL/(info['file_name'].rsplit('.',1)[0]+'.txt')).write_text('\\n'.join(lines))\n",
        "            kept+=1\n",
        "        else:\n",
        "            try: imgp.unlink()\n",
        "            except: pass\n",
        "    print('kept',kept)\n",
        "\n",
        "coco2yolo(train_ids, imgs_tr, anns_tr, Path('train'), Path('train'))\n",
        "coco2yolo(val_ids,   imgs_va, anns_va, Path('val'),   Path('val'))\n",
        "\n",
        "(Path('dataset.yaml')\n",
        " .write_text(f\"path: {base_dir.resolve()}\\ntrain: images/train\\nval: images/val\\nnc: {len(TARGET)}\\nnames: {TARGET}\\n\"))\n",
        "print('dataset.yaml pronto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHie6bX4Ahxd",
        "outputId": "bad1f175-57ea-4590-c86e-3c1516f2ac16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "baixando train: 100%|██████████| 284/284 [01:11<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok 277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "baixando val: 100%|██████████| 72/72 [00:14<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "labels train: 100%|██████████| 284/284 [00:00<00:00, 4654.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kept 284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "labels val: 100%|██████████| 72/72 [00:00<00:00, 3980.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kept 72\n",
            "dataset.yaml pronto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino rápido em CPU (20 épocas) — YOLOv8n\n",
        "!pip -q install ultralytics==8.3.188\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # nano, mais leve no CPU\n",
        "\n",
        "FAST = dict(\n",
        "    data='dataset.yaml',\n",
        "    epochs=20,          # <-- como você pediu\n",
        "    imgsz=512,          # mais rápido que 768\n",
        "    batch=8,            # se travar, teste 6 ou 4\n",
        "    device='cpu',\n",
        "    workers=2,          # não exagere no CPU\n",
        "    val=False,          # <-- desliga validação por época (grande ganho)\n",
        "    cache=True,         # cache de imagens acelera muito os próximos epochs\n",
        "    rect=True,          # batches retangulares (melhor packing)\n",
        "    multi_scale=False,  # mantém 512 fixo\n",
        "    amp=False,          # CPU\n",
        "    save_period=0,      # não salvar checkpoint a cada época\n",
        "\n",
        "    # Otimização/aug leves (evita custo extra e instabilidade)\n",
        "    mosaic=0.0, mixup=0.0,\n",
        "    degrees=0.0, translate=0.05, scale=0.20, shear=0.0,\n",
        "    hsv_h=0.01, hsv_s=0.30, hsv_v=0.30,\n",
        "\n",
        "    # Opt de treino estável\n",
        "    optimizer='AdamW', lr0=0.002, lrf=0.02, weight_decay=0.0005,\n",
        "    cos_lr=True, close_mosaic=0,\n",
        ")\n",
        "\n",
        "results = model.train(**FAST)\n",
        "\n",
        "# Validação única no final (com plots)\n",
        "metrics = model.val(data='dataset.yaml', imgsz=512, conf=0.001, iou=0.60, plots=True)\n",
        "print({\n",
        "    \"P\": float(metrics.box.mp),\n",
        "    \"R\": float(metrics.box.mr),\n",
        "    \"mAP50\": float(metrics.box.map50),\n",
        "    \"mAP50-95\": float(metrics.box.map),\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CynK4qozajcn",
        "outputId": "485de041-35f0-489a-a406-175cec64fa2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hNew https://pypi.org/project/ultralytics/8.3.189 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=0, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01, hsv_s=0.3, hsv_v=0.3, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.02, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=0, save_txt=False, scale=0.2, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 26.0±9.5 MB/s, size: 71.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train.cache... 558 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 558/558 703251.7it/s 0.0s\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB RAM): 100% ━━━━━━━━━━━━ 558/558 191.0it/s 2.9s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 29.2±13.0 MB/s, size: 56.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val.cache... 130 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 130/130 176688.1it/s 0.0s\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% ━━━━━━━━━━━━ 130/130 210.1it/s 0.6s\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 512 train, 512 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20         0G      2.029       3.06      1.736          9        352: 100% ━━━━━━━━━━━━ 70/70 0.31it/s 3:45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20         0G      2.066      2.797      1.857          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20         0G      2.062      2.722      1.851          8        352: 100% ━━━━━━━━━━━━ 70/70 0.32it/s 3:38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20         0G      2.076      2.661      1.834          8        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20         0G      2.011      2.544       1.78          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20         0G      1.944      2.501      1.778          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20         0G      1.992      2.417      1.781          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20         0G       1.88      2.326      1.718          9        352: 100% ━━━━━━━━━━━━ 70/70 0.32it/s 3:35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20         0G      1.756       2.11      1.632          8        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20         0G      1.726      2.032      1.598          7        352: 100% ━━━━━━━━━━━━ 70/70 0.32it/s 3:36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20         0G      1.602      1.899      1.514          8        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20         0G      1.583      1.814      1.497          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20         0G      1.541      1.753      1.464          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20         0G      1.469      1.623       1.42          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20         0G      1.425      1.563      1.365          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20         0G      1.366      1.473      1.348          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20         0G      1.332      1.408      1.316          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20         0G      1.294       1.34      1.295          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20         0G      1.297      1.323       1.28          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20         0G      1.271      1.303      1.288          9        352: 100% ━━━━━━━━━━━━ 70/70 0.33it/s 3:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 9/9 0.42it/s 21.2s\n",
            "                   all        130        254      0.473      0.323       0.31       0.16\n",
            "\n",
            "20 epochs completed in 1.199 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 9/9 0.48it/s 18.8s\n",
            "                   all        130        254      0.473      0.323      0.309       0.16\n",
            "               bicycle         74        131      0.546      0.321      0.322      0.175\n",
            "                 truck         71        123      0.401      0.325      0.297      0.144\n",
            "Speed: 3.8ms preprocess, 135.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1109.7±439.7 MB/s, size: 53.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val.cache... 130 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 130/130 194042.5it/s 0.0s\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% ━━━━━━━━━━━━ 130/130 362.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 1.0it/s 16.8s\n",
            "                   all        130        254      0.511      0.328      0.331      0.166\n",
            "               bicycle         74        131      0.611      0.321      0.359      0.184\n",
            "                 truck         71        123      0.412      0.336      0.303      0.148\n",
            "Speed: 1.1ms preprocess, 123.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "{'P': 0.5111643655915884, 'R': 0.3280841721148312, 'mAP50': 0.3312841166578078, 'mAP50-95': 0.1659943165167172}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYYhgIvA6AbjMJ1DJTAbWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}